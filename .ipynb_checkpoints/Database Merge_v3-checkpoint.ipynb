{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PURPOSE\\n\\nThe purpose of this code is to attempt to merge the Starr account data located in Saleforce with that of the \\ncompany information located in Capital IQ.\\n\\nData Sources  = Two Excel spreadsheets, ene from Capital IQ and the other from Salesforce. \\nUnique ID's   = Capital IQ will be the CIQ ID\\n                Salesforce will be the Ultimate Parent D&B number. \\n\\nApproach      = TBD\\n\\nQuestions   \\n1.) Does every company in our dataset have a CIQ and D&B number?\\n2.) Does every company in our dataset have a state, city and zip code?\\n\\nDate:    02.10.2018\\nauthor:  Chris Cirelli\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PURPOSE\n",
    "\n",
    "The purpose of this code is to attempt to merge the Starr account data located in Saleforce with that of the \n",
    "company information located in Capital IQ.\n",
    "\n",
    "Data Sources  = Two Excel spreadsheets, ene from Capital IQ and the other from Salesforce. \n",
    "Unique ID's   = Capital IQ will be the CIQ ID\n",
    "                Salesforce will be the Ultimate Parent D&B number. \n",
    "\n",
    "Approach      = TBD\n",
    "\n",
    "Questions   \n",
    "1.) Does every company in our dataset have a CIQ and D&B number?\n",
    "2.) Does every company in our dataset have a state, city and zip code?\n",
    "\n",
    "Date:    02.10.2018\n",
    "author:  Chris Cirelli\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GitHub\\Starr-Project')\n",
    "import Module_Starr_DataMerger as msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE LOCATION OF FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Capital IQ Match w Salesforce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salesforce Data\n",
    "df_CIQ = pd.read_excel('Private Company Target List 2062018.xls')\n",
    "\n",
    "# Capital IQ Data\n",
    "df_SF = pd.read_excel('Salesforce Data Dump - Capital IQ Merger.xlsx')\n",
    "df_SF = df_SF[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ANALYTICS TABLE (DAT) CIQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Purpose:  Limit the CIQ Dataframe to only those values needed to facilitate the matching\n",
    "'''\n",
    "\n",
    "DAT_CIQ = df_CIQ[['Excel Company ID', 'Company Name', 'Primary State', 'Primary City', 'Primary Zip Code/Postal Code']]\n",
    "\n",
    "DAT_SF = df_SF[['Client Ultimate Parent DUNS Number', 'Company Name', 'Billing State/Province', 'Billing City', \n",
    "                'Billing Zip/Postal Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE NONE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Values in dataframe:  DAT_CIQ \n",
      " {'Excel Company ID': 0, 'Company Name': 0, 'Primary State': 0, 'Primary City': 0, 'Primary Zip Code/Postal Code': 0}\n",
      "\n",
      "None Values in dataframe:  DAT_SF \n",
      " {'Client Ultimate Parent DUNS Number': 0, 'Company Name': 0, 'Billing State/Province': 0, 'Billing City': 0, 'Billing Zip/Postal Code': 0}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Purpose:  See if we are missing any values in our dataframe that need to be relplaced or removed. \n",
    "Import:   Create & import the get_nanValues function from the module 'msd'.\n",
    "'''\n",
    "\n",
    "print('None Values in dataframe:  DAT_CIQ', '\\n',  msd.get_nanValues(DAT_CIQ))\n",
    "print('')\n",
    "print('None Values in dataframe:  DAT_SF', '\\n', msd.get_nanValues(DAT_SF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FIRST AND SECOND COMPANY NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38813\n",
      "38813\n",
      "38813\n"
     ]
    }
   ],
   "source": [
    "'''The purpose of this code is to extract from the Company Name column in each dataset the first and second name of\n",
    "    each company.  In addition, punctuation like a ',' and '.' will need to be removed. \n",
    "   \n",
    "    Modules =  Create and import the get_company_name() function from the msd module. \n",
    "    Input   =  To generate the first and second name, the code needs to be run twice on the same dataframe.  Each time, \n",
    "              the user needs to identify the dataframe and then the name (First / Second) that they want to obtain. \n",
    "    Output  =  A list of every company name for either the first or second name. \n",
    "   \n",
    "    date:   02.10.2018\n",
    "    author: Chris Cirelli\n",
    "'''\n",
    "\n",
    "# CIQ Dataframe\n",
    "DAT_CIQ_list_first_Name = msd.get_company_name(DAT_CIQ, 'First').copy()\n",
    "DAT_CIQ_list_second_Name = msd.get_company_name(DAT_CIQ, 'Second').copy()\n",
    "\n",
    "# SF Dataframe\n",
    "DAT_SF_list_first_Name = msd.get_company_name(DAT_SF, 'First').copy()\n",
    "DAT_SF_list_Second_Name = msd.get_company_name(DAT_SF, 'Second').copy()\n",
    "\n",
    "# Error Check = Verify Lenghts of Lists\n",
    "'''List lengths need to equal the length of the columns in the dataframe to properly append'''\n",
    "\n",
    "print(len(DAT_SF['Company Name']))\n",
    "print(len(DAT_SF_list_first_Name))\n",
    "print(len(DAT_SF_list_Second_Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECREATE DATAFRAMES WITH FIRST AND SECOND NAMES APPENDED. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "'''The purpose of this code is to append the first and second name lists that we created to the CIQ and SF Dataframes'''\n",
    "\n",
    "DAT_SF['Company First Name'] = DAT_SF_list_first_Name\n",
    "DAT_SF['Company Second Name'] = DAT_SF_list_Second_Name\n",
    "DAT_CIQ['Company First Name'] = DAT_CIQ_list_first_Name\n",
    "DAT_CIQ['Company Second Name'] = DAT_CIQ_list_second_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARMONIZE ZIP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "'''The purpose of this code is to harmonize the format of the zip codes between the two datasets. \n",
    "\n",
    "    Modules = create and import the clean_zip_code() module from msd. \n",
    "    Input   = a.) a string value of the dataframe (ex 'DAT_CIQ') to tell the module which dataframe to work with. \n",
    "             b.) the target dataframe. \n",
    "    Output  = A list with each zip code harmonized \n",
    "   \n",
    "    date:   02.10.2018\n",
    "    author: Chris Cirelli\n",
    "'''\n",
    "\n",
    "# Create list of harmonized zipCodes. \n",
    "DAT_CIQ_ZIP = msd.clean_zip_Code('DAT_CIQ', DAT_CIQ)\n",
    "DAT_SF_ZIP = msd.clean_zip_Code('DAT_SF', DAT_SF)\n",
    "\n",
    "# Append lists to the CIQ and SF dataframes. \n",
    "DAT_CIQ['Zip Code Clean'] = DAT_CIQ_ZIP\n",
    "DAT_SF['Zip Code Clean'] = DAT_SF_ZIP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_v4(DAT_CIQ, DAT_SF):\n",
    "    \n",
    "   \n",
    "    # Target Dataframes\n",
    "    CIQ_dataframe = DAT_CIQ\n",
    "    SF_dataframe = DAT_SF\n",
    "    \n",
    "    # Create a tuple for each row in the dataframe. \n",
    "    CIQ = [x for x in CIQ_dataframe.itertuples()]         \n",
    "    SF = [x[8] for x in SF_dataframe.itertuples()]       # Note the indexing of x to pull the zipCode.   \n",
    "    \n",
    "    # List to capture Dataframes\n",
    "    \n",
    "    List_matching_records = []\n",
    "    \n",
    "    # Loop over each row of the CIQ Dataframe. \n",
    "    for row_CIQ in CIQ:\n",
    "        \n",
    "        # Identify original index of the target row in the CIQ dataframe. \n",
    "        row_CIQ_Index = row_CIQ[0]\n",
    "        \n",
    "        # if row_CIQ[8], the zipCOde is in row_SF[8], zipCode, then...\n",
    "        if row_CIQ[8] in SF:\n",
    "                         \n",
    "            # Limit SF dataframe to only those records that have the CIQ zip code\n",
    "            SF_limit = DAT_SF['Zip Code Clean'] == row_CIQ[8]\n",
    "            # Define new SF Dataframe\n",
    "            SF_limited_zip = DAT_SF[SF_limit]\n",
    "            # Create a new SF tupple object from the SF limited dataframe. \n",
    "            SF_2 = [x[6] for x in SF_limited_zip.itertuples()]\n",
    "            \n",
    "            \n",
    "            # See if the first name of the same company in question is in the SF dataframe\n",
    "            if row_CIQ[6] in SF_2:\n",
    "                        \n",
    "                # Limit the SF Dataframe to only those records that have the CIQ first company name\n",
    "                SF_limit = SF_limited_zip['Company First Name'] == row_CIQ[6]\n",
    "                # Define new SF Dataframe\n",
    "                SF_limited_firstName = SF_limited_zip[SF_limit]\n",
    "                # Create a new SF tupple object from the SF limited dataframe. \n",
    "                SF_3 = [x[7] for x in SF_limited_firstName.itertuples()]\n",
    "                        \n",
    "    \n",
    "                # Check to see if there is a match with the second name from our original CIQ dataframe\n",
    "                if row_CIQ[7] in SF_3:\n",
    "                            \n",
    "                    # Limit the SF Dataframe to only those records that have the CIQ second company name\n",
    "                    SF_limit = SF_limited_firstName['Company Second Name'] == row_CIQ[7]\n",
    "                    # Define Final SF Dataframe\n",
    "                    SF_matching_record = SF_limited_firstName[SF_limit]\n",
    "                    SF_matching_record_0 = SF_matching_record.iloc[:1]\n",
    "                    \n",
    "                    SF_matching_record_resetIndex = SF_matching_record_0.reset_index()\n",
    "                    \n",
    "                    SF_matching_record_resetIndex.iloc[:,0] = row_CIQ_Index\n",
    "                    \n",
    "                    List_matching_records.append(SF_matching_record_resetIndex)\n",
    "                    \n",
    "    return List_matching_records\n",
    "                    \n",
    "                \n",
    "                                \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match = get_match_v4(DAT_CIQ, DAT_SF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mult_dataframes_to_Excel(List_dataframes, filename):\n",
    "    \n",
    "    import pandas\n",
    "    \n",
    "    # Define Writer\n",
    "    writer = pd.ExcelWriter(filename+'.xlsx')\n",
    "    \n",
    "    # Define Count\n",
    "    \n",
    "    Count = 0\n",
    "    \n",
    "    # Loop over dataframes\n",
    "    for df in List_dataframes:\n",
    "        df.to_excel(writer, sheet_name = 'Data', startrow = Count, header = None)\n",
    "        # Keep count\n",
    "        Count += 1\n",
    "    writer.save()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = write_mult_dataframes_to_Excel(Match, 'Starr Proejct - Matching Records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Excel = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Capital IQ Match w Salesforce\\Starr Proejct - Matching Records.xlsx', \n",
    "                           header = None)\n",
    "\n",
    "df_matches = pd.DataFrame(Match_Excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_matches.drop(0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Client Ultimate Parent DUNS Number', 'Company Name',\n",
       "       'Billing State/Province', 'Billing City', 'Billing Zip/Postal Code',\n",
       "       'Company First Name', 'Company Second Name', 'Zip Code Clean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAT_SF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.columns = ['Index', 'Client Ultimate Parent DUNS Number', 'Company Name',\n",
    "       'Billing State/Province', 'Billing City', 'Billing Zip/Postal Code',\n",
    "       'Company First Name', 'Company Second Name', 'Zip Code Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_2.set_index('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Merged_Dataframe = DAT_CIQ.merge(df3, left_index = True, right_index = True, suffixes=('_CapitalIQ', '_Salesforce'), how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel(dataframe, filename):\n",
    "    import pandas as pd\n",
    "    writer = pd.ExcelWriter(filename+'.xlsx')\n",
    "    dataframe.to_excel(writer, sheet_name = 'Data')\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(Final_Merged_Dataframe, 'Final_DF_CIQ_SF_Merger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Excel Company ID</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Primary State</th>\n",
       "      <th>Primary City</th>\n",
       "      <th>Primary Zip Code/Postal Code</th>\n",
       "      <th>Company First Name</th>\n",
       "      <th>Company Second Name</th>\n",
       "      <th>Zip Code Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IQ184468</td>\n",
       "      <td>Mars, Incorporated</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>McLean</td>\n",
       "      <td>22101</td>\n",
       "      <td>Mars</td>\n",
       "      <td>Incorporated</td>\n",
       "      <td>22101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Excel Company ID        Company Name Primary State Primary City  \\\n",
       "0         IQ184468  Mars, Incorporated      Virginia       McLean   \n",
       "\n",
       "  Primary Zip Code/Postal Code Company First Name Company Second Name  \\\n",
       "0                        22101               Mars        Incorporated   \n",
       "\n",
       "  Zip Code Clean  \n",
       "0          22101  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAT_CIQ.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client Ultimate Parent DUNS Number</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Billing State/Province</th>\n",
       "      <th>Billing City</th>\n",
       "      <th>Billing Zip/Postal Code</th>\n",
       "      <th>Company First Name</th>\n",
       "      <th>Company Second Name</th>\n",
       "      <th>Zip Code Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51957769.0</td>\n",
       "      <td>Wal-Mart Stores, Inc.</td>\n",
       "      <td>AR</td>\n",
       "      <td>Bentonville</td>\n",
       "      <td>72716-6299</td>\n",
       "      <td>Wal-Mart</td>\n",
       "      <td>Stores</td>\n",
       "      <td>72716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Client Ultimate Parent DUNS Number           Company Name  \\\n",
       "0                          51957769.0  Wal-Mart Stores, Inc.   \n",
       "\n",
       "  Billing State/Province Billing City Billing Zip/Postal Code  \\\n",
       "0                     AR  Bentonville              72716-6299   \n",
       "\n",
       "  Company First Name Company Second Name Zip Code Clean  \n",
       "0           Wal-Mart              Stores          72716  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAT_SF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
