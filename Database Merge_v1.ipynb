{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PURPOSE\\n\\nThe purpose of this code is to attempt to merge the Starr account data located in Saleforce with that of the \\ncompany information located in Capital IQ.\\n\\nData Sources  = Two Excel spreadsheets, ene from Capital IQ and the other from Salesforce. \\nUnique ID's   = Capital IQ will be the CIQ ID\\n                Salesforce will be the Ultimate Parent D&B number. \\n\\nApproach      = TBD\\n\\nQuestions   \\n1.) Does every company in our dataset have a CIQ and D&B number?\\n2.) Does every company in our dataset have a state, city and zip code?\\n\\nDate:    02.10.2018\\nauthor:  Chris Cirelli\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PURPOSE\n",
    "\n",
    "The purpose of this code is to attempt to merge the Starr account data located in Saleforce with that of the \n",
    "company information located in Capital IQ.\n",
    "\n",
    "Data Sources  = Two Excel spreadsheets, ene from Capital IQ and the other from Salesforce. \n",
    "Unique ID's   = Capital IQ will be the CIQ ID\n",
    "                Salesforce will be the Ultimate Parent D&B number. \n",
    "\n",
    "Approach      = TBD\n",
    "\n",
    "Questions   \n",
    "1.) Does every company in our dataset have a CIQ and D&B number?\n",
    "2.) Does every company in our dataset have a state, city and zip code?\n",
    "\n",
    "Date:    02.10.2018\n",
    "author:  Chris Cirelli\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GitHub\\Starr-Project')\n",
    "import Module_Starr_DataMerger as msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE LOCATION OF FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Capital IQ Match w Salesforce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salesforce Data\n",
    "df_CIQ = pd.read_excel('Private Company Target List 2062018.xls')\n",
    "\n",
    "# Capital IQ Data\n",
    "df_SF = pd.read_excel('Salesforce Data Dump - Capital IQ Merger.xlsx')\n",
    "df_SF = df_SF[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ANALYTICS TABLE (DAT) CIQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Purpose:  Limit the CIQ Dataframe to only those values needed to facilitate the matching\n",
    "'''\n",
    "\n",
    "DAT_CIQ = df_CIQ[['Excel Company ID', 'Company Name', 'Primary State', 'Primary City', 'Primary Zip Code/Postal Code']]\n",
    "\n",
    "DAT_SF = df_SF[['Client Ultimate Parent DUNS Number', 'Company Name', 'Billing State/Province', 'Billing City', \n",
    "                'Billing Zip/Postal Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE NONE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Values in dataframe:  DAT_CIQ \n",
      " {'Excel Company ID': 0, 'Company Name': 0, 'Primary State': 0, 'Primary City': 0, 'Primary Zip Code/Postal Code': 0}\n",
      "\n",
      "None Values in dataframe:  DAT_SF \n",
      " {'Client Ultimate Parent DUNS Number': 0, 'Company Name': 0, 'Billing State/Province': 0, 'Billing City': 0, 'Billing Zip/Postal Code': 0}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Purpose:  See if we are missing any values in our dataframe that need to be relplaced or removed. \n",
    "Import:   Create & import the get_nanValues function from the module 'msd'.\n",
    "'''\n",
    "\n",
    "print('None Values in dataframe:  DAT_CIQ', '\\n',  msd.get_nanValues(DAT_CIQ))\n",
    "print('')\n",
    "print('None Values in dataframe:  DAT_SF', '\\n', msd.get_nanValues(DAT_SF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FIRST AND SECOND COMPANY NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38813\n",
      "38813\n",
      "38813\n"
     ]
    }
   ],
   "source": [
    "'''The purpose of this code is to extract from the Company Name column in each dataset the first and second name of\n",
    "    each company.  In addition, punctuation like a ',' and '.' will need to be removed. \n",
    "   \n",
    "    Modules =  Create and import the get_company_name() function from the msd module. \n",
    "    Input   =  To generate the first and second name, the code needs to be run twice on the same dataframe.  Each time, \n",
    "              the user needs to identify the dataframe and then the name (First / Second) that they want to obtain. \n",
    "    Output  =  A list of every company name for either the first or second name. \n",
    "   \n",
    "    date:   02.10.2018\n",
    "    author: Chris Cirelli\n",
    "'''\n",
    "\n",
    "# CIQ Dataframe\n",
    "DAT_CIQ_list_first_Name = msd.get_company_name(DAT_CIQ, 'First').copy()\n",
    "DAT_CIQ_list_second_Name = msd.get_company_name(DAT_CIQ, 'Second').copy()\n",
    "\n",
    "# SF Dataframe\n",
    "DAT_SF_list_first_Name = msd.get_company_name(DAT_SF, 'First').copy()\n",
    "DAT_SF_list_Second_Name = msd.get_company_name(DAT_SF, 'Second').copy()\n",
    "\n",
    "# Error Check = Verify Lenghts of Lists\n",
    "'''List lengths need to equal the length of the columns in the dataframe to properly append'''\n",
    "\n",
    "print(len(DAT_SF['Company Name']))\n",
    "print(len(DAT_SF_list_first_Name))\n",
    "print(len(DAT_SF_list_Second_Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECREATE DATAFRAMES WITH FIRST AND SECOND NAMES APPENDED. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "'''The purpose of this code is to append the first and second name lists that we created to the CIQ and SF Dataframes'''\n",
    "\n",
    "DAT_SF['Company First Name'] = DAT_SF_list_first_Name\n",
    "DAT_SF['Company Second Name'] = DAT_SF_list_Second_Name\n",
    "DAT_CIQ['Company First Name'] = DAT_CIQ_list_first_Name\n",
    "DAT_CIQ['Company Second Name'] = DAT_CIQ_list_second_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARMONIZE ZIP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Module_Starr_DataMerger' has no attribute 'clean_zip_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3d52e3b7e2b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Create list of harmonized zipCodes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mDAT_CIQ_ZIP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_zip_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DAT_CIQ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDAT_CIQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mDAT_SF_ZIP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_zip_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DAT_SF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDAT_SF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Module_Starr_DataMerger' has no attribute 'clean_zip_code'"
     ]
    }
   ],
   "source": [
    "'''The purpose of this code is to harmonize the format of the zip codes between the two datasets. \n",
    "\n",
    "    Modules = create and import the clean_zip_code() module from msd. \n",
    "    Input   = a.) a string value of the dataframe (ex 'DAT_CIQ') to tell the module which dataframe to work with. \n",
    "             b.) the target dataframe. \n",
    "    Output  = A list with each zip code harmonized \n",
    "   \n",
    "    date:   02.10.2018\n",
    "    author: Chris Cirelli\n",
    "'''\n",
    "\n",
    "# Create list of harmonized zipCodes. \n",
    "DAT_CIQ_ZIP = msd.clean_zip_code('DAT_CIQ', DAT_CIQ)\n",
    "DAT_SF_ZIP = msd.clean_zip_code('DAT_SF', DAT_SF)\n",
    "\n",
    "# Append lists to the CIQ and SF dataframes. \n",
    "DAT_CIQ['Zip Code Clean'] = DAT_CIQ_ZIP\n",
    "DAT_SF['Zip Code Clean'] = DAT_SF_ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIQ_head = DAT_CIQ.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_v2():\n",
    "    '''The purpose of this code is to match records from the SF and CIQ dataframes. \n",
    "    Input  = The CIQ and SF Dataframes.  Requires that these dataframes were pre-cleaned by the codes included in the\n",
    "             Module_Starr_Datamerge file. \n",
    "    Output = The DAT_CIQ Dataframe with the matching values appended to each row. \n",
    "    \n",
    "    Date:    02.10.2018\n",
    "    author:  Chris Cirelli\n",
    "    '''\n",
    "    \n",
    "    # Create a tuple for each row in the dataframe. \n",
    "    CIQ = [x for x in CIQ_head.itertuples()]         # Rever back to DAT CIQ when finished testing. \n",
    "    SF = [x for x in DAT_SF.itertuples()]\n",
    "    \n",
    "    # Loop over each row of the CIQ Dataframe. \n",
    "    for row_CIQ in CIQ:\n",
    "        \n",
    "        # Get the index value for the target CIQ row.  Use this at end of code. \n",
    "        row_CIQ_index_value = row_CIQ.index\n",
    "        \n",
    "        # Loop over each row of the SF Dataframe. \n",
    "        for row_SF in SF:\n",
    "            if row_CIQ[8] in row_SF[8]:\n",
    "            \n",
    "                # Limit SF dataframe to only those records that have the CIQ zip code\n",
    "                SF_limit = DAT_SF['Zip Code Clean'] == row_CIQ[8]\n",
    "                # Define new SF Dataframe\n",
    "                SF_limited_zip = DAT_SF[SF_limit]\n",
    "                # Create a new SF tupple object from the SF limited dataframe. \n",
    "                SF_2 = [x for x in SF_limited_zip.itertuples()]\n",
    "                \n",
    "                # Iterate over new SF dataframe\n",
    "                for row_SF2 in SF_2:\n",
    "                    # See if the first name of the same company in question is in the SF dataframe\n",
    "                    if row_CIQ[6] in row_SF2[6]:\n",
    "                        \n",
    "                        # Limit the SF Dataframe to only those records that have the CIQ first company name\n",
    "                        SF_limit = SF_limited_zip['Company First Name'] == row_SF2[6]\n",
    "                        # Define new SF Dataframe\n",
    "                        SF_limited_firstName = SF_limited_zip[SF_limit]\n",
    "                        # Create a new SF tupple object from the SF limited dataframe. \n",
    "                        SF_3 = [x for x in SF_limited_firstName.itertuples()]\n",
    "                        \n",
    "                        \n",
    "                        # Iterate over new SF dataframe\n",
    "                        for row_SF3 in SF_3:\n",
    "                            \n",
    "                            # Check to see if there is a match with the second name from our original CIQ dataframe\n",
    "                            if row_CIQ[7] in row_SF3[7]:\n",
    "                            \n",
    "                                # Limit the SF Dataframe to only those records that have the CIQ second company name\n",
    "                                SF_limit = SF_limited_firstName['Company Second Name'] == row_SF3[7]\n",
    "                                # Define Final SF Dataframe\n",
    "                                SF_Final = SF_limited_firstName[SF_limit]\n",
    "                        \n",
    "                                return SF_Final\n",
    "                        \n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matching_record = get_match_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_index_value = Matching_record.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matching_record.index = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Requirements to merge\n",
    "\n",
    "DAT_CIQ dataframe\n",
    "Matching record from our get_match() function\n",
    "Matching record - set index to the same value as that of the DAT_CIQ record. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = DAT_CIQ, \n",
    "         right = Matching_record, \n",
    "         left_index = True, \n",
    "         right_index = True, \n",
    "         how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
