{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PURPOSE\\n\\nThe purpose of this code is to attempt to merge the Starr account data located in Saleforce with that of the \\ncompany information located in Capital IQ.\\n\\nData Sources  = Two Excel spreadsheets, ene from Capital IQ and the other from Salesforce. \\nUnique ID's   = Capital IQ will be the CIQ ID\\n                Salesforce will be the Ultimate Parent D&B number. \\n\\nApproach      = TBD\\n\\nQuestions   \\n1.) Does every company in our dataset have a CIQ and D&B number?\\n2.) Does every company in our dataset have a state, city and zip code?\\n\\nDate:    02.07.2018\\nauthor:  Chris Cirelli\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PURPOSE\n",
    "\n",
    "The purpose of this code is to attempt to merge the Starr account data located in Saleforce with that of the \n",
    "company information located in Capital IQ.\n",
    "\n",
    "Data Sources  = Two Excel spreadsheets, ene from Capital IQ and the other from Salesforce. \n",
    "Unique ID's   = Capital IQ will be the CIQ ID\n",
    "                Salesforce will be the Ultimate Parent D&B number. \n",
    "\n",
    "Approach      = TBD\n",
    "\n",
    "Questions   \n",
    "1.) Does every company in our dataset have a CIQ and D&B number?\n",
    "2.) Does every company in our dataset have a state, city and zip code?\n",
    "\n",
    "Date:    02.07.2018\n",
    "author:  Chris Cirelli\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GitHub\\Starr-Project')\n",
    "import Module_Starr_DataMerger as msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Capital IQ Match w Salesforce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salesforce Data\n",
    "df_CIQ = pd.read_excel('Private Company Target List 2062018.xls')\n",
    "\n",
    "# Capital IQ Data\n",
    "df_SF = pd.read_excel('Salesforce Data Dump - Capital IQ Merger.xlsx')\n",
    "df_SF = df_SF[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ANALYTICS TABLE (DAT) CAPITAL IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datapoints = Client Name, Client Ultimate Parent DUNS Number, Billing City, Billing State/Province, \n",
    "Billing Zip/Postal Code'''\n",
    "\n",
    "DAT_CIQ = df_CIQ[['Excel Company ID', 'Company Name', 'Primary State', 'Primary City', 'Primary Zip Code/Postal Code']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT_SF = df_SF[['Client Ultimate Parent DUNS Number', 'Company Name', 'Billing State/Province', 'Billing City', \n",
    "                'Billing Zip/Postal Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_company = DAT_SF['Company Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE NONE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Values in dataframe:  DAT_CIQ \n",
      " {'Excel Company ID': 0, 'Company Name': 0, 'Primary State': 0, 'Primary City': 0, 'Primary Zip Code/Postal Code': 0}\n",
      "\n",
      "None Values in dataframe:  DAT_SF \n",
      " {'Client Ultimate Parent DUNS Number': 0, 'Company Name': 0, 'Billing State/Province': 0, 'Billing City': 0, 'Billing Zip/Postal Code': 0}\n"
     ]
    }
   ],
   "source": [
    "print('None Values in dataframe:  DAT_CIQ', '\\n',  msd.get_nanValues(DAT_CIQ))\n",
    "print('')\n",
    "print('None Values in dataframe:  DAT_SF', '\\n', msd.get_nanValues(DAT_SF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FIRST AND SECOND COMPANY NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT_CIQ_list_first_Name = msd.get_company_name(DAT_CIQ, 'First').copy()\n",
    "DAT_CIQ_list_second_Name = msd.get_company_name(DAT_CIQ, 'Second').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT_SF_list_first_Name = msd.get_company_name(DAT_SF, 'First').copy()\n",
    "DAT_SF_list_Second_Name = msd.get_company_name(DAT_SF, 'Second').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Lenghts of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append First and Second Names to Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38813\n",
      "38813\n",
      "38813\n"
     ]
    }
   ],
   "source": [
    "print(len(DAT_SF['Company Name']))\n",
    "print(len(DAT_SF_list_first_Name))\n",
    "print(len(DAT_SF_list_Second_Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECREATE DATAFRAMES WITH FIRST AND SECOND NAMES APPENDED. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "DAT_SF['Company First Name'] = DAT_SF_list_first_Name\n",
    "DAT_SF['Company Second Name'] = DAT_SF_list_Second_Name\n",
    "DAT_CIQ['Company First Name'] = DAT_CIQ_list_first_Name\n",
    "DAT_CIQ['Company Second Name'] = DAT_CIQ_list_second_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN UP ZIP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "DAT_CIQ_ZIP = msd.clean_zip_code('DAT_CIQ', DAT_CIQ)\n",
    "DAT_CIQ['Zip Code Clean'] = DAT_CIQ_ZIP\n",
    "DAT_SF_ZIP = msd.clean_zip_code('DAT_SF', DAT_SF)\n",
    "DAT_SF['Zip Code Clean'] = DAT_SF_ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME MERGE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(CIQ_Dataframe, SF_Dataframe):\n",
    "    \n",
    "    \n",
    "    # ITERATE OVER CIQ ZIP COLUMN\n",
    "    for zipCode in CIQ_Dataframe['Zip Code Clean']:\n",
    "\n",
    "        \n",
    "        # Check to see if there is a match in the SF Dataframe\n",
    "        if zipCode in SF_Dataframe['Zip Code Clean']:\n",
    "            print('match')\n",
    "        \n",
    "            # Limit CIQ & SF Dataframes by the matching zipCode \n",
    "            CIQ_limit_zip = CIQ_Dataframe['Zip Code Clean'] == zipCode\n",
    "            SF_limit_zip = SF_Dataframe['Zip Code Clean'] == zipCode\n",
    "            \n",
    "            # Create the new CIQ & SF Dataframes\n",
    "            CIQ_Dataframe_limit_by_zip = CIQ_Dataframe[CIQ_limit_zip]\n",
    "            \n",
    "            \n",
    "            SF_Dataframe_limit_by_zip = SF_Dataframe[SF_limit_zip]\n",
    "            \n",
    "            \n",
    "            # ITERATE OVER THE NEW CIQ DATAFRAME FOR COMPANY FIRST NAME\n",
    "            for coName in CIQ_Dataframe_limit_by_zip['Company First Name']:\n",
    "                \n",
    "                # Check to see if there is a match in the SF Dataframe\n",
    "                if coName in SF_Dataframe_limit_by_zip['Company First Name']:\n",
    "                    \n",
    "                    \n",
    "                    # Limit the CIQ & SF Dataframes by the matching First coNames \n",
    "                    CIQ_limit_coName = CIQ_Dataframe_limit_by_zip['Company First Name'] == coName\n",
    "                    SF_limit_coName = SF_Dataframe_limit_by_zip['Company First Name'] == coName\n",
    "                    \n",
    "                    # Create new CIQ & SF Dataframes\n",
    "                    CIQ_Dataframe_limit_by_coName = CIQ_Dataframe_limit_by_zip[CIQ_limit_coName]\n",
    "                    SF_Dataframe_limit_by_coName = SF_Dataframe_limit_by_zip[SF_limit_coName]\n",
    "            \n",
    "                    \n",
    "                    #  ITERATE OVER NEW CIQ DATAFRAME FOR COMPANY SECOND NAME \n",
    "                    for sec_coName in CIQ_Dataframe_limit_by_coName['Company Second Name']:\n",
    "                        \n",
    "                        # Check if there is a match in the SF Dataframe\n",
    "                        if sec_coName in SF_Dataframe_limit_by_coName['Company Second Name']:\n",
    "                            \n",
    "                            # Limit CIQ & SF Dataframes by the Second coName\n",
    "                            CIQ_limit_sec_coName = CIQ_Dataframe_limit_by_coName['Company Second Name'] == sec_coName\n",
    "                            SF_limit_sec_coName = SF_Dataframe_limit_by_coName['Company Second Name'] == sec_coName\n",
    "                            \n",
    "                            # Create New CIQ and SF Dataframes Limited by Second coName\n",
    "                            CIQ_limit_by_sec_coName = CIQ_Dataframe_limit_by_coName[CIQ_limit_sec_coName]\n",
    "                            SF_limit_sec_coName = SF_Dataframe_limit_by_coName[SF_limit_sec_coName]\n",
    "                            \n",
    "                            \n",
    "                            # DEFINE YOUR FINAL DATAFRAME BY APPENDING THE DATA FROM THE CIQ MATCH TO THE SF DATAFRAMEa\n",
    "                            Final_SF_Dataframe = SF_limit_sec_coName.append(CIQ_limit_by_sec_coName)\n",
    "                            \n",
    "                            return Final_SF_Dataframe\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-98f0aeac4f78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDAT_CIQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDAT_SF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-92-fcfa3428402e>\u001b[0m in \u001b[0;36mget_match\u001b[1;34m(CIQ_Dataframe, SF_Dataframe)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Check to see if there is a match in the SF Dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mzipCode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSF_Dataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Zip Code Clean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'match'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__contains__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    905\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[1;34m\"\"\"True if the key is in the info axis\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__contains__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1588\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__contains__'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_index_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1590\u001b[1;33m         \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1591\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         raise TypeError('{0!r} objects are mutable, thus they cannot be'\n\u001b[1;32m--> 877\u001b[1;33m                         ' hashed'.format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "Test = get_match(DAT_CIQ, DAT_SF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Client Ultimate Parent DUNS Number              5.19578e+07\n",
       "Company Name                          Wal-Mart Stores, Inc.\n",
       "Billing State/Province                                   AR\n",
       "Billing City                                    Bentonville\n",
       "Billing Zip/Postal Code                          72716-6299\n",
       "Company First Name                                 Wal-Mart\n",
       "Company Second Name                                  Stores\n",
       "Zip Code Clean                                        72716\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF_row = DAT_SF.loc[0]\n",
    "SF_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIQ_row = DAT_CIQ.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Client Ultimate Parent DUNS Number              5.19578e+07\n",
       "Company Name                          Wal-Mart Stores, Inc.\n",
       "Billing State/Province                                   AR\n",
       "Billing City                                    Bentonville\n",
       "Billing Zip/Postal Code                          72716-6299\n",
       "Company First Name                                 Wal-Mart\n",
       "Company Second Name                                  Stores\n",
       "Zip Code Clean                                        72716\n",
       "Excel Company ID                                   IQ184468\n",
       "Company Name                             Mars, Incorporated\n",
       "Primary State                                      Virginia\n",
       "Primary City                                         McLean\n",
       "Primary Zip Code/Postal Code                          22101\n",
       "Company First Name                                     Mars\n",
       "Company Second Name                            Incorporated\n",
       "Zip Code Clean                                        22101\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF_row.append(CIQ_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CODE TO MERGE DATA SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT_SF_match = msd.get_match(DAT_CIQ, DAT_SF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
